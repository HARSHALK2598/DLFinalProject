
Model loaded from checkpoint.
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 64, 128, 128]           1,792
              ReLU-2         [-1, 64, 128, 128]               0
            Conv2d-3         [-1, 64, 128, 128]          36,928
              ReLU-4         [-1, 64, 128, 128]               0
         MaxPool2d-5           [-1, 64, 64, 64]               0
            Conv2d-6          [-1, 128, 64, 64]          73,856
              ReLU-7          [-1, 128, 64, 64]               0
            Conv2d-8          [-1, 128, 64, 64]         147,584
              ReLU-9          [-1, 128, 64, 64]               0
        MaxPool2d-10          [-1, 128, 32, 32]               0
           Conv2d-11          [-1, 256, 32, 32]         295,168
             ReLU-12          [-1, 256, 32, 32]               0
           Conv2d-13          [-1, 256, 32, 32]         590,080
             ReLU-14          [-1, 256, 32, 32]               0
           Conv2d-15          [-1, 256, 32, 32]         590,080
             ReLU-16          [-1, 256, 32, 32]               0
        MaxPool2d-17          [-1, 256, 16, 16]               0
           Conv2d-18          [-1, 512, 16, 16]       1,180,160
             ReLU-19          [-1, 512, 16, 16]               0
           Conv2d-20          [-1, 512, 16, 16]       2,359,808
             ReLU-21          [-1, 512, 16, 16]               0
           Conv2d-22          [-1, 512, 16, 16]       2,359,808
             ReLU-23          [-1, 512, 16, 16]               0
        MaxPool2d-24            [-1, 512, 8, 8]               0
           Conv2d-25            [-1, 512, 8, 8]       2,359,808
             ReLU-26            [-1, 512, 8, 8]               0
           Conv2d-27            [-1, 512, 8, 8]       2,359,808
             ReLU-28            [-1, 512, 8, 8]               0
           Conv2d-29            [-1, 512, 8, 8]       2,359,808
             ReLU-30            [-1, 512, 8, 8]               0
AdaptiveAvgPool2d-31            [-1, 512, 7, 7]               0
           Linear-32                    [-1, 4]         100,356
================================================================
Total params: 14,815,044
Trainable params: 100,356
Non-trainable params: 14,714,688
----------------------------------------------------------------
Input size (MB): 0.19
Forward/backward pass size (MB): 71.44
Params size (MB): 56.51
Estimated Total Size (MB): 128.14
----------------------------------------------------------------
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 3, 128, 128]              84
              ReLU-2          [-1, 3, 128, 128]               0
            Conv2d-3          [-1, 3, 128, 128]              84
              ReLU-4          [-1, 3, 128, 128]               0
         MaxPool2d-5            [-1, 3, 64, 64]               0
            Conv2d-6            [-1, 3, 64, 64]              84
              ReLU-7            [-1, 3, 64, 64]               0
            Conv2d-8            [-1, 3, 64, 64]              84
              ReLU-9            [-1, 3, 64, 64]               0
        MaxPool2d-10            [-1, 3, 32, 32]               0
          Flatten-11                 [-1, 3072]               0
           Linear-12                    [-1, 4]          12,292
================================================================
Total params: 12,628
Trainable params: 12,628
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.19
Forward/backward pass size (MB): 2.02
Params size (MB): 0.05
Estimated Total Size (MB): 2.25
----------------------------------------------------------------


Teacher Model : Test loss: 0.1318, Test acc: 95.43%




  0%|          | 0/50 [00:00<?, ?it/s]/ext3/miniconda3/lib/python3.12/site-packages/torch/nn/functional.py:2976: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(

  2%|▏         | 1/50 [02:51<2:19:53, 171.30s/it]
  4%|▍         | 2/50 [03:16<1:08:04, 85.10s/it] 
  6%|▌         | 3/50 [03:40<45:07, 57.62s/it]  
  8%|▊         | 4/50 [04:05<34:15, 44.68s/it]
 10%|█         | 5/50 [04:30<28:10, 37.57s/it]
 12%|█▏        | 6/50 [04:55<24:21, 33.21s/it]
 14%|█▍        | 7/50 [05:20<21:47, 30.40s/it]
 16%|█▌        | 8/50 [05:44<19:59, 28.56s/it]
 18%|█▊        | 9/50 [06:09<18:37, 27.26s/it]
 20%|██        | 10/50 [06:33<17:35, 26.39s/it]
 22%|██▏       | 11/50 [06:58<16:45, 25.78s/it]
 24%|██▍       | 12/50 [07:22<16:02, 25.34s/it]
 26%|██▌       | 13/50 [07:47<15:34, 25.25s/it]
 28%|██▊       | 14/50 [08:12<15:08, 25.25s/it]
 30%|███       | 15/50 [08:37<14:35, 25.00s/it]
 32%|███▏      | 16/50 [09:01<14:08, 24.97s/it]
 34%|███▍      | 17/50 [09:26<13:40, 24.85s/it]
 36%|███▌      | 18/50 [09:51<13:12, 24.76s/it]
 38%|███▊      | 19/50 [10:15<12:46, 24.71s/it]
 40%|████      | 20/50 [10:40<12:20, 24.67s/it]
 42%|████▏     | 21/50 [11:04<11:52, 24.56s/it]
 44%|████▍     | 22/50 [11:28<11:23, 24.42s/it]
 46%|████▌     | 23/50 [11:53<10:59, 24.44s/it]
 48%|████▊     | 24/50 [12:18<10:40, 24.62s/it]
 50%|█████     | 25/50 [12:43<10:18, 24.74s/it]
 52%|█████▏    | 26/50 [13:07<09:54, 24.75s/it]
 54%|█████▍    | 27/50 [13:32<09:25, 24.60s/it]
 56%|█████▌    | 28/50 [13:56<08:59, 24.54s/it]
 58%|█████▊    | 29/50 [14:21<08:35, 24.54s/it]
 60%|██████    | 30/50 [14:45<08:10, 24.54s/it]
 62%|██████▏   | 31/50 [15:10<07:46, 24.55s/it]
 64%|██████▍   | 32/50 [15:34<07:21, 24.54s/it]
 66%|██████▌   | 33/50 [15:58<06:54, 24.39s/it]
 68%|██████▊   | 34/50 [16:23<06:32, 24.51s/it]
 70%|███████   | 35/50 [16:48<06:10, 24.72s/it]
 72%|███████▏  | 36/50 [17:13<05:46, 24.72s/it]
 74%|███████▍  | 37/50 [17:38<05:21, 24.75s/it]
 76%|███████▌  | 38/50 [18:02<04:56, 24.69s/it]
 78%|███████▊  | 39/50 [18:27<04:30, 24.56s/it]
 80%|████████  | 40/50 [18:51<04:05, 24.54s/it]
 82%|████████▏ | 41/50 [19:16<03:40, 24.53s/it]
 84%|████████▍ | 42/50 [19:40<03:16, 24.53s/it]
 86%|████████▌ | 43/50 [20:04<02:51, 24.45s/it]
 88%|████████▊ | 44/50 [20:29<02:26, 24.42s/it]
 90%|█████████ | 45/50 [20:54<02:03, 24.64s/it]
 92%|█████████▏| 46/50 [21:19<01:38, 24.71s/it]
 94%|█████████▍| 47/50 [21:44<01:14, 24.79s/it]
 96%|█████████▌| 48/50 [22:08<00:49, 24.72s/it]
 98%|█████████▊| 49/50 [22:33<00:24, 24.64s/it]
100%|██████████| 50/50 [22:57<00:00, 24.60s/it]
100%|██████████| 50/50 [22:57<00:00, 27.56s/it]
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Epoch: 0
-------
Train loss: 0.44781 | Train acc: 69.40%
Test loss: 0.3385, Test acc: 78.35%

Epoch: 1
-------
Train loss: 0.27149 | Train acc: 83.39%
Test loss: 0.3174, Test acc: 78.12%

Epoch: 2
-------
Train loss: 0.22378 | Train acc: 86.48%
Test loss: 0.3034, Test acc: 81.55%

Epoch: 3
-------
Train loss: 0.19419 | Train acc: 88.25%
Test loss: 0.2204, Test acc: 87.20%

Epoch: 4
-------
Train loss: 0.16190 | Train acc: 90.20%
Test loss: 0.2233, Test acc: 86.13%

Epoch: 5
-------
Train loss: 0.13556 | Train acc: 92.02%
Test loss: 0.2288, Test acc: 86.43%

Epoch: 6
-------
Train loss: 0.11714 | Train acc: 93.10%
Test loss: 0.1911, Test acc: 88.49%

Epoch: 7
-------
Train loss: 0.09945 | Train acc: 94.29%
Test loss: 0.1877, Test acc: 90.24%

Epoch: 8
-------
Train loss: 0.08942 | Train acc: 94.71%
Test loss: 0.2074, Test acc: 88.95%

Epoch: 9
-------
Train loss: 0.07684 | Train acc: 95.61%
Test loss: 0.2149, Test acc: 89.18%

Epoch: 10
-------
Train loss: 0.06142 | Train acc: 96.62%
Test loss: 0.1779, Test acc: 91.31%

Epoch: 11
-------
Train loss: 0.05735 | Train acc: 96.97%
Test loss: 0.2005, Test acc: 90.24%

Epoch: 12
-------
Train loss: 0.04738 | Train acc: 97.46%
Test loss: 0.2347, Test acc: 90.24%

Epoch: 13
-------
Train loss: 0.04203 | Train acc: 97.93%
Test loss: 0.2324, Test acc: 90.40%

Epoch: 14
-------
Train loss: 0.03938 | Train acc: 98.09%
Test loss: 0.2223, Test acc: 89.86%

Epoch: 15
-------
Train loss: 0.04372 | Train acc: 97.69%
Test loss: 0.2865, Test acc: 87.73%

Epoch: 16
-------
Train loss: 0.03756 | Train acc: 98.23%
Test loss: 0.2164, Test acc: 91.92%

Epoch: 17
-------
Train loss: 0.02686 | Train acc: 98.91%
Test loss: 0.2461, Test acc: 91.08%

Epoch: 18
-------
Train loss: 0.02930 | Train acc: 98.74%
Test loss: 0.2662, Test acc: 90.09%

Epoch: 19
-------
Train loss: 0.02223 | Train acc: 99.33%
Test loss: 0.2550, Test acc: 91.08%

Epoch: 20
-------
Train loss: 0.03141 | Train acc: 98.67%
Test loss: 0.2700, Test acc: 89.25%

Epoch: 21
-------
Train loss: 0.03317 | Train acc: 98.35%
Test loss: 0.2357, Test acc: 90.55%

Epoch: 22
-------
Train loss: 0.02208 | Train acc: 99.40%
Test loss: 0.2456, Test acc: 92.07%

Epoch: 23
-------
Train loss: 0.01740 | Train acc: 99.68%
Test loss: 0.2570, Test acc: 92.15%


tensor([1, 3, 1, 2, 2, 2, 1, 3, 0, 3, 0, 2])
